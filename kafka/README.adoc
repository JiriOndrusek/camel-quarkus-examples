= Kafka example : A Camel Quarkus example
:cq-example-description: An example that shows how to produce and consume messages in a Kafka topic, created on a Kafka cluster with OpenShift Streams for Apache Kafka.

{cq-description}

TIP: Check the https://camel.apache.org/camel-quarkus/latest/first-steps.html[Camel Quarkus User guide] for prerequisites
and other general information.


== Prerequisites

This quickstart assumes that you already have access to Red Hat OpenShift Streams for Apache Kafka[https://developers.redhat.com/products/red-hat-openshift-streams-for-apache-kafka/getting-started].

== Provision a Kafka cluster with OpenShift Streams for Apache Kafka
You can provision either using the UI or RHOAS cli, as decribed in following sections

== Provision a Kafka cluster with Openshift Streams for Apache Kafka using UI
1. Go to https://cloud.redhat.com/application-services[cloud.redhat.com], and log with your Red Hat account, or create one.
2. Create a new Kafka instance, following the https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/f351c4bd-9840-42ef-bcf2-b0c9be4ee30a#_b4f95791-b992-429d-9e8e-cceb63ae829f[Creating a Kafka instance in OpenShift Streams for Apache Kafka Guide].
3. Create a topic named `test` following the https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/f351c4bd-9840-42ef-bcf2-b0c9be4ee30a#_e7458089-1dfe-4d51-bfd0-990014e7226c[Creating a Kafka topic in OpenShift Streams for Apache Kafka Guide].
4. Create a set of credentials, following the https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/f351c4bd-9840-42ef-bcf2-b0c9be4ee30a#_7cb5e3f0-4b76-408d-b245-ff6959d3dbf7[Creating a service account to connect to a Kafka instance in OpenShift Streams for Apache Kafka Guide].

== Provision a Kafka cluster with Openshift Streams for Apache Kafka using RHOAS cli
1. Install the https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/f520e427-cad2-40ce-823d-96234ccbc047#_8818f0d5-ae20-42c8-9622-a98e663ff1a8[Red Hat OpenShift Application Services command-line interface (CLI)].
2. Login to Openshift Streams for Apache Kafka, following the https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/f520e427-cad2-40ce-823d-96234ccbc047#_e081dde5-54e8-4cd2-81e5-4a53bf1f4338[Logging in to rhoas Guide].
3. Create a new Kafka instance, following the https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/f520e427-cad2-40ce-823d-96234ccbc047#_creating_a_kafka_instance[Creating a Kafka instance Guide].
4. Create a topic named `test` following the https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/f520e427-cad2-40ce-823d-96234ccbc047#_creating_a_kafka_topic[Creating a Kafka topic Guide].
5. Create a set of credentials, following the https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/f520e427-cad2-40ce-823d-96234ccbc047#_creating_a_service_account[Creating a service account Guide].

== Set the right Kafka client credentials
If you want to connect to your Kafka instance using SASL Plain, you'd need to uncomment the Kafka credentials with SASL Plain section in `src/main/resources/application.properties`.

[source,shell]
----
camel.component.kafka.brokers=<YOUR_KAFKA_BROKERS_URL>
camel.component.kafka.security-protocol=SASL_SSL
camel.component.kafka.sasl-mechanism=PLAIN
camel.component.kafka.sasl-jaas-config=org.apache.kafka.common.security.plain.PlainLoginModule required username="<YOUR_KAFKA_SASL_CLIENT_ID>" password="<YOUR_KAFKA_SASL_CLIENT_SECRET>";
----
- Change YOUR_KAFKA_SASL_CLIENT_ID by the Client ID
- Change YOUR_KAFKA_SASL_CLIENT_SECRET by the Client Secret
- Change YOUR_KAFKA_BROKERS_URL by the Bootstrap server


If you want to connect to your Kafka instance using SASL Oauth Bearer, you'd need to uncomment the Kafka credentials with SASL Oauth Bearer section in `src/main/resources/application.properties`.

[source,shell]
----
camel.component.kafka.brokers = <YOUR_KAFKA_BROKERS_URL>
camel.component.kafka.security-protocol = SASL_SSL
camel.component.kafka.sasl-mechanism = OAUTHBEARER
camel.component.kafka.sasl-jaas-config = org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
        oauth.client.id="<YOUR_KAFKA_SASL_CLIENT_ID>" \
        oauth.client.secret="<YOUR_KAFKA_SASL_CLIENT_SECRET>" \
        oauth.token.endpoint.uri="<YOUR_KAFKA_SASL_OAUTHBEARER_TOKEN_URL>" ;
camel.component.kafka.additional-properties[sasl.login.callback.handler.class] = io.strimzi.kafka.oauth.client.JaasClientOauthLoginCallbackHandler
----
- Change YOUR_KAFKA_SASL_CLIENT_ID by the Client ID
- Change YOUR_KAFKA_SASL_CLIENT_SECRET by the Client Secret
- Change YOUR_KAFKA_BROKERS_URL by the Bootstrap server
- Change YOUR_KAFKA_SASL_OAUTHBEARER_TOKEN_URL by the SASL/OAUTHBEARER Token endpoint URL

== Start in Development mode

Run the application in development mode.

[source,shell]
----
$ mvn clean compile quarkus:dev
----

The above command compiles the project, starts the application and lets the Quarkus tooling watch for changes in your
workspace. Any modifications in your project will automatically take effect in the running application.


TIP: Please refer to the Development mode section of
https://camel.apache.org/camel-quarkus/latest/first-steps.html#_development_mode[Camel Quarkus User guide] for more details.

You should start to see some log messages appearing on the console.

Every 10 seconds the timer component triggers the generation of random Message and send it to the Kafka topic `Test`.

[source,shell]
----
[FromTimer2Kafka] (Camel (camel-1) thread #2 - KafkaProducer[test]) Message sent correctly sent to the topic! : "Message #1"
----

Next a Kafka consumer reads the messages and put them in a seda queue.

[source,shell]
----
[FromKafka2Seda] (Camel (camel-1) thread #0 - KafkaConsumer[test]) Received : "Message #1"
----

Next pull a message from the queue :
[source,shell]
----
$ curl -X GET http://0.0.0.0:8080/example
----


=== Package and run the application

Once you are done with developing you may want to package and run the application.

[source,shell]
----
$ mvn clean package -DskipTests
$ java -jar target/*-runner.jar
----

==== Deploying to OpenShift
Create a new project named `camel-kafka-ns`.

[source,shell]
----
$ oc new-project camel-kafka-ns
----

To deploy the application to OpenShift run the following command.

[source,shell]
----
$ mvn clean package -DskipTests -Dquarkus.kubernetes.deploy=true
----

[NOTE]
====
If you need to configure container resource limits & requests, or enable the Quarkus Kubernetes client to trust self signed certificates, you can find these configuration options in `src/main/resources/application.properties`. Simply uncomment them and set your desired values.
====

Check the pod is running.

[source,shell]
----
$ oc get pods
NAME                                           READY   STATUS    RESTARTS   AGE
camel-quarkus-examples-kafka-dbc56974b-ph29m   1/1     Running   0          2m34s
----

Tail the application logs.

[source,shell]
----
$ oc logs -f camel-quarkus-examples-kafka-dbc56974b-ph29m
----

Get the service route.
[source,shell]
----
$ oc get route camel-quarkus-examples-kafka
----

Next use the route, to pull a message from the queue :
[source,shell]
----
$ curl -X GET <YOUR_ROUTE>/example
----

To clean up do.

[source,shell]
----
$ oc delete all -l app.kubernetes.io/name=camel-quarkus-examples-kafka
$ oc delete project camel-kafka-ns
----

For more information about deploying Quarkus applications to OpenShift, refer to the https://access.redhat.com/documentation/en-us/red_hat_build_of_quarkus/1.11/html/deploying_your_quarkus_applications_to_openshift/ref-openshift-build-strategies-and-quarkus_quarkus-openshift[documentation].




